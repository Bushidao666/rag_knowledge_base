#!/usr/bin/env python3
"""
Example 02: RAG vs Alternatives Comparison
==========================================

Este exemplo compara RAG com alternativas: Fine-tuning, Pure Generative,
e Vector Search Only.

Uso:
    python example-02-rag-vs-alternatives.py
"""

import os
from typing import List, Dict
from langchain.llms import OpenAI
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import Chroma
from langchain.chains import RetrievalQA


class RAGApproach:
    """ImplementaÃ§Ã£o RAG"""
    def __init__(self, documents: List[str]):
        self.embeddings = OpenAIEmbeddings()
        self.llm = OpenAI(temperature=0)
        self.vectorstore = Chroma.from_texts(documents, self.embeddings)
        self.qa = RetrievalQA.from_chain_type(
            llm=self.llm,
            retriever=self.vectorstore.as_retriever(k=3)
        )

    def query(self, question: str) -> str:
        result = self.qa.run(question)
        return result


class PureGenerativeApproach:
    """Pure Generative - apenas LLM, sem retrieval"""
    def __init__(self):
        self.llm = OpenAI(temperature=0.7)

    def query(self, question: str) -> str:
        prompt = f"""
Pergunta: {question}

Resposta (baseada no conhecimento geral do modelo):
"""
        return self.llm(prompt)


class VectorSearchOnlyApproach:
    """Vector Search Only - sem LLM, sÃ³ busca"""
    def __init__(self, documents: List[str]):
        self.embeddings = OpenAIEmbeddings()
        self.vectorstore = Chroma.from_texts(documents, self.embeddings)

    def query(self, question: str) -> str:
        docs = self.vectorstore.similarity_search(question, k=3)
        context = "\n\n".join([doc.page_content for doc in docs])
        return f"Documentos relacionados encontrados:\n\n{context}"


class FineTuningApproach:
    """Fine-tuning - LLM treinado com dados especÃ­ficos"""
    def __init__(self):
        self.llm = OpenAI(
            model_name="gpt-3.5-turbo-fine-tuned",
            temperature=0
        )

    def query(self, question: str) -> str:
        # Simular fine-tuned model
        prompt = f"Q: {question}\nA:"
        return self.llm(prompt)


def compare_approaches(question: str, documents: List[str]):
    """Compara todas as abordagens"""
    print(f"\n{'='*60}")
    print(f"Pergunta: {question}")
    print(f"{'='*60}\n")

    # 1. RAG
    print("1ï¸âƒ£  RAG (Retrieval-Augmented Generation)")
    print("-" * 60)
    try:
        rag = RAGApproach(documents)
        result = rag.query(question)
        print(f"Resposta: {result}")
        print(f"âœ… Vantagens: Context-aware, factual, citations")
        print(f"âš ï¸  Desvantagens: Complexidade, latÃªncia extra")
    except Exception as e:
        print(f"âŒ Erro: {e}")
        print("   (Requer OpenAI API key)")

    # 2. Pure Generative
    print("\n2ï¸âƒ£  Pure Generative (SÃ³ LLM)")
    print("-" * 60)
    try:
        pure = PureGenerativeApproach()
        result = pure.query(question)
        print(f"Resposta: {result}")
        print(f"âœ… Vantagens: Simples, rÃ¡pido, barato")
        print(f"âš ï¸  Desvantagens: Hallucinations, knowledge limitado")
    except Exception as e:
        print(f"âŒ Erro: {e}")

    # 3. Vector Search
    print("\n3ï¸âƒ£  Vector Search Only (SÃ³ busca)")
    print("-" * 60)
    try:
        vector = VectorSearchOnlyApproach(documents)
        result = vector.query(question)
        print(f"Resposta: {result}")
        print(f"âœ… Vantagens: RÃ¡pido, nÃ£o gera, factual")
        print(f"âš ï¸  Desvantagens: Sem geraÃ§Ã£o, contexto limitado")
    except Exception as e:
        print(f"âŒ Erro: {e}")

    # 4. Fine-tuning
    print("\n4ï¸âƒ£  Fine-tuning (LLM treinado)")
    print("-" * 60)
    try:
        fine = FineTuningApproach()
        result = fine.query(question)
        print(f"Resposta: {result}")
        print(f"âœ… Vantagens: Alto desempenho, especializado")
        print(f"âš ï¸  Desvantagens: Caro, estÃ¡tico, complexo")
    except Exception as e:
        print(f"âŒ Erro: {e}")


def comparison_matrix():
    """Exibe matriz de comparaÃ§Ã£o"""
    print(f"\n{'='*80}")
    print("MATRIZ DE COMPARAÃ‡ÃƒO")
    print(f"{'='*80}")

    matrix = """
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CritÃ©rio     â”‚ RAG      â”‚ Fine-tuning  â”‚ Pure Gen â”‚ Vector Searchâ”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Conhecimento â”‚ External â”‚ ParamÃ©trico  â”‚ Param.   â”‚ External     â”‚
â”‚              â”‚ + Param. â”‚              â”‚          â”‚              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ AtualizaÃ§Ã£o  â”‚ FÃ¡cil    â”‚ Caro         â”‚ Imposs.  â”‚ FÃ¡cil        â”‚
â”‚              â”‚ (update) â”‚ (re-train)   â”‚          â”‚ (update)     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Custo        â”‚ Baixo-   â”‚ Alto         â”‚ Baixo    â”‚ Baixo        â”‚
â”‚              â”‚ MÃ©dio    â”‚              â”‚          â”‚              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Performance  â”‚ Alta     â”‚ Muito Alta   â”‚ MÃ©dia    â”‚ Alta         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Hallucinationâ”‚ Menor    â”‚ Pode         â”‚ Freq.    â”‚ NÃ£o          â”‚
â”‚              â”‚          â”‚ ocorrer      â”‚          â”‚              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Citations    â”‚ Sim      â”‚ NÃ£o          â”‚ NÃ£o      â”‚ Sim          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
"""
    print(matrix)


def when_to_use_which():
    """Explica quando usar cada abordagem"""
    print(f"\n{'='*80}")
    print("QUANDO USAR CADA ABORDAGEM")
    print(f"{'='*80}\n")

    recommendations = {
        "RAG": {
            "use_when": [
                "âœ… Knowledge up-to-date Ã© crÃ­tico",
                "âœ… Dados mudam frequentemente",
                "âœ… Precisa de citations/explicabilidade",
                "âœ… Volume de dados Ã© grande",
                "âœ… Custo de re-treino Ã© alto"
            ],
            "dont_use_when": [
                "âŒ DomÃ­nio bem restrito e estÃ¡tico",
                "âŒ Performance mÃ¡xima Ã© prioridade"
            ]
        },
        "Fine-tuning": {
            "use_when": [
                "âœ… DomÃ­nio bem definido e estÃ¡vel",
                "âœ… Tem budget e time para treinar",
                "âœ… Performance mÃ¡xima Ã© crÃ­tica",
                "âœ… NÃ£o precisa de citations"
            ],
            "dont_use_when": [
                "âŒ Dados mudam frequentemente",
                "âŒ Budget/tempo limitado"
            ]
        },
        "Pure Generative": {
            "use_when": [
                "âœ… Tarefas criativas",
                "âœ… NÃ£o precisa de factualidade",
                "âœ… Knowledge geral Ã© suficiente"
            ],
            "dont_use_when": [
                "âŒ Precisa de informaÃ§Ãµes factuais",
                "âŒ Domain-specific knowledge"
            ]
        },
        "Vector Search": {
            "use_when": [
                "âœ… Busca semÃ¢ntica",
                "âœ… NÃ£o precisa de geraÃ§Ã£o",
                "âœ… Apenas recuperar documentos"
            ],
            "dont_use_when": [
                "âŒ Precisa de sÃ­ntese/gerar texto",
                "âŒ Respostas complexas necessÃ¡rias"
            ]
        }
    }

    for approach, details in recommendations.items():
        print(f"\nğŸ¯ {approach.upper()}:")
        for item in details["use_when"]:
            print(f"   {item}")
        print("   Quando NÃƒO usar:")
        for item in details["dont_use_when"]:
            print(f"   {item}")


def main():
    """FunÃ§Ã£o principal"""
    print("=" * 80)
    print("RAG vs ALTERNATIVES - ComparaÃ§Ã£o de Abordagens")
    print("=" * 80)

    # Documentos de exemplo
    documents = [
        "RAG combina memÃ³ria paramÃ©trica e nÃ£o-paramÃ©trica",
        "RAG reduz hallucinations em sistemas de QA",
        "Lewis et al. (2020) introduziu RAG para NLP",
        "RAG permite knowledge up-to-date sem re-treinar"
    ]

    # Perguntas de teste
    questions = [
        "O que Ã© RAG?",
        "Como RAG reduz hallucinations?",
        "Quem introduziu RAG?"
    ]

    # Exibir matriz de comparaÃ§Ã£o
    comparison_matrix()

    # Exibir recomendaÃ§Ãµes
    when_to_use_which()

    # Comparar abordagens
    for question in questions:
        compare_approaches(question, documents)

    print("\n" + "=" * 80)
    print("CONCLUSÃƒO")
    print("=" * 80)
    print("""
RAG Ã© ideal quando vocÃª precisa de:
- Knowledge factual e up-to-date
- Explicabilidade (citations)
- Custo-efetividade
- Flexibilidade

Escolha alternativas se:
- DomÃ­nio estÃ¡tico â†’ Fine-tuning
- Performance mÃ¡xima â†’ Fine-tuning
- Tarefas criativas â†’ Pure Generative
- SÃ³ busca â†’ Vector Search
""")
    print("=" * 80)


if __name__ == "__main__":
    main()
