# Quick Start: Chunking Strategies

**Tempo estimado:** 15-30 minutos
**N√≠vel:** Iniciante
**Pr√©-requisitos:** Documentos para processar

## Objetivo
Aprender estrat√©gias de chunking para otimizar retrieval e gera√ß√£o

## O que √© Chunking?
Dividir documentos grandes em chunks menores para melhor retrieval:
```
Documento Grande ‚Üí Chunks (1000 chars) ‚Üí Embeddings ‚Üí Vector DB
```

## Por que Chunking?

1. **Context Window Limit** - LLMs t√™m limite de tokens
2. **Melhor Precision** - Chunks menores = mais relevantes
3. **Custo Eficiente** - Menos tokens = menor custo
4. **Precis√£o Sem√¢ntica** - Chunks coesos melhoram similarity

## RecursiveCharacterTextSplitter (Padr√£o)

```python
from langchain.text_splitters import RecursiveCharacterTextSplitter

splitter = RecursiveCharacterTextSplitter(
    chunk_size=1000,      # Tamanho ideal
    chunk_overlap=200,    # Preserva contexto
    separators=["\n\n", "\n", ".", " "]
)

chunks = splitter.split_documents(documents)
```

## Par√¢metros Importantes

### chunk_size
- **Padr√£o:** 1000 caracteres (~250 tokens)
- **Menor (500):** Mais chunks, maior precis√£o
- **Maior (2000):** Menos chunks, mais contexto

### chunk_overlap
- **Padr√£o:** 200 caracteres
- **Fun√ß√£o:** Preservar contexto entre chunks
- **Resultado:** Evitar informa√ß√£o cortada

### separators
Ordem de prioridade para split:
1. `\n\n` (par√°grafos)
2. `\n` (linhas)
3. `.` (frases)
4. ` ` (palavras)

## Estrat√©gias de Chunking

### 1. Fixed Size
Mais simples, baseado apenas em tamanho:
```python
from langchain.text_splitters import CharacterTextSplitter

splitter = CharacterTextSplitter(
    chunk_size=1000,
    chunk_overlap=200
)
```

### 2. Semantic
Baseado em significado:
```python
from langchain.text_splitters import SentenceTransformersTokenizer

# Divide por senten√ßas
splitter = SentenceTransformersTokenizer(
    chunk_size=1000,
    chunk_overlap=200
)
```

### 3. Hierarchical
M√∫ltiplos n√≠veis:
```python
from langchain.text_splitters import (
    TitleElementSplitter,
    HeaderElementSplitter
)

# Primeiro por headers
header_splitter = HeaderElementSplitter()

# Depois por p√°r√°grafos
paragraph_splitter = RecursiveCharacterTextSplitter(
    chunk_size=1000,
    chunk_overlap=200
)
```

## Exemplo Completo

```python
from langchain.document_loaders import TextLoader
from langchain.text_splitters import RecursiveCharacterTextSplitter
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import Chroma

# 1. Load document
loader = TextLoader("documento.txt")
docs = loader.load()

# 2. Split into chunks
splitter = RecursiveCharacterTextSplitter(
    chunk_size=1000,
    chunk_overlap=200
)
chunks = splitter.split_documents(docs)

# 3. Create vector store
embeddings = OpenAIEmbeddings()
vectorstore = Chroma.from_documents(chunks, embeddings)

print(f"Documento dividido em {len(chunks)} chunks")
```

## Par√¢metros por Caso de Uso

### Q&A System
- **chunk_size:** 1000
- **chunk_overlap:** 200
- **Separa√ß√£o:** `\n\n`, `\n`, `.`

### Summarization
- **chunk_size:** 2000-3000
- **chunk_overlap:** 500
- **Separa√ß√£o:** `\n\n`

### Code Analysis
- **chunk_size:** 500
- **chunk_overlap:** 100
- **Separa√ß√£o:** `\n\n`, fun√ß√£o, classe

### Conversational AI
- **chunk_size:** 800
- **chunk_overlap:** 150
- **Separa√ß√£o:** `\n\n`, `\n`

## Compara√ß√£o Estrat√©gias

| Estrat√©gia | Pr√≥s | Contras | Quando Usar |
|------------|------|---------|-------------|
| **Recursive** | Flexible, default | Pode quebrar estruturas | Geral |
| **Fixed** | Simples, r√°pido | Perde contexto | Textos simples |
| **Semantic** | Preserva significado | Lento | Textos complexos |
| **Hierarchical** | Estrutura preservada | Complexo | Documentos t√©cnicos |

## Custom Splitter

```python
from langchain.text_splitters import TextSplitter

class CustomTextSplitter(TextSplitter):
    def split_text(self, text):
        # Sua l√≥gica customizada
        return custom_split_logic(text)

# Uso
splitter = CustomTextSplitter(
    chunk_size=1000,
    chunk_overlap=200
)
```

## Troubleshooting

### Chunks muito pequenos
**Problema:** Perdendo contexto
**Solu√ß√£o:** Aumentar chunk_size
```python
splitter = RecursiveCharacterTextSplitter(
    chunk_size=1500,  # Aumentar
    chunk_overlap=300
)
```

### Chunks muito grandes
**Problema:** Retrieval impreciso
**Solu√ß√£o:** Diminuir chunk_size
```python
splitter = RecursiveCharacterTextSplitter(
    chunk_size=500,  # Diminuir
    chunk_overlap=100
)
```

### Contexto perdido entre chunks
**Problema:** Respostas incompletas
**Solu√ß√£o:** Aumentar overlap
```python
splitter = RecursiveCharacterTextSplitter(
    chunk_size=1000,
    chunk_overlap=300  # Aumentar
)
```

## Pr√≥ximos Passos

- üìñ **Tutorial Avan√ßado:** [Hierarchical Chunking](../tutorials/)
- üíª **Code Examples:** [V√°rios Exemplos](../code-examples/)
- üîß **Troubleshooting:** [Problemas Comuns](../troubleshooting/common-issues.md)

## Recursos

- üìÑ **LangChain Splitters:** https://python.langchain.com/docs/modules/text_splitters/
- üìä **Comparison Matrix:** [Best Practices](../best-practices/dos-donts.md)
- üéØ **Document Processing:** [Guia 01](../01-Document-Processing/README.md)
